{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('onegin.txt', 'r') as iofile:\n",
    "    text = iofile.readlines()\n",
    "    \n",
    "text = \"\".join([x.replace('\\t\\t', '').lower() for x in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_tokens: 84\n"
     ]
    }
   ],
   "source": [
    "SOS_TOKEN = '<sos>'\n",
    "tokens = sorted(set(text.lower())) + [SOS_TOKEN]\n",
    "\n",
    "num_tokens = len(tokens)\n",
    "\n",
    "print(f\"num_tokens: {num_tokens}\")\n",
    "\n",
    "token_to_index = {token : index for index, token in enumerate(tokens)}\n",
    "index_to_token = {index : token for index, token in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_indices = [token_to_index[token] for token in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_chunk(batch_size, seq_length):\n",
    "    text_len = len(text)\n",
    "    # start_index in [0, text_len - seq_length - 1]\n",
    "    start_indices = np.random.randint(low=0, high=text_len - seq_length, size=batch_size)\n",
    "    random_chunks = [[token_to_index[SOS_TOKEN]] + text_indices[start_index:start_index + seq_length] for start_index in start_indices]\n",
    "    random_chunks = np.array(random_chunks)\n",
    "    assert random_chunks.shape == (batch_size, seq_length + 1)\n",
    "    return random_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_check_shapes(lhs_shape, rhs_shape):\n",
    "    assertion_message = f\"Not equal shapes: {lhs_shape} instead of {rhs_shape}\"\n",
    "    assert lhs_shape == rhs_shape, assertion_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell(nn.Module):\n",
    "    def __init__(self, num_tokens, embedding_size, hidden_embedding_size):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.num_tokens = num_tokens\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_embedding_size = hidden_embedding_size\n",
    "\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=num_tokens, embedding_dim=embedding_size)\n",
    "\n",
    "        # input shape:              (batch_size, 1)\n",
    "        # with embeds shape:        (batch_size, embedding_size)\n",
    "        # last hidden state shape:  (batch_size, hidden_embedding_size)\n",
    "        self.W_to_new_hidden = nn.Linear(embedding_size + hidden_embedding_size, hidden_embedding_size)\n",
    "        self.W_to_raw_logits = nn.Linear(hidden_embedding_size, num_tokens)\n",
    "\n",
    "    def forward(self, input, last_hidden_state):\n",
    "        batch_size = input.shape[0]\n",
    "\n",
    "        # (batch, embedding_size)\n",
    "        input_embeddings = self.embedding_layer(input).squeeze(dim=1)\n",
    "        assert_check_shapes(\n",
    "            input_embeddings.shape, \n",
    "            (batch_size, self.embedding_size)\n",
    "        )\n",
    "\n",
    "        # (batch, embedding_size + hidden_embedding_size)\n",
    "        concat_input_and_last_hidden = torch.cat([input, last_hidden_state], dim=-1)\n",
    "        assert_check_shapes(\n",
    "            concat_input_and_last_hidden.shape, \n",
    "            (batch_size, self.embedding_size + self.hidden_embedding_size)\n",
    "        )\n",
    "\n",
    "        # (batch, hidden_embedding_size)\n",
    "        new_hidden_state = self.W_to_new_hidden(concat_input_and_last_hidden)\n",
    "        assert_check_shapes(\n",
    "            new_hidden_state.shape, (batch_size, self.hidden_embedding_size)\n",
    "        )\n",
    "\n",
    "        # (batch, num_tokens)\n",
    "        raw_logits = self.W_to_raw_logits(new_hidden_state)\n",
    "        assert_check_shapes(\n",
    "            raw_logits.shape, \n",
    "            (batch_size, self.num_tokens)\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'raw_logits' : raw_logits,\n",
    "            'hidden_state' : new_hidden_state\n",
    "        }\n",
    "    \n",
    "    def get_start_state(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_embedding_size, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 32\n",
    "hidden_embedding_size = 48\n",
    "batch_size = 8\n",
    "seq_length = 16\n",
    "\n",
    "rnn_cell = RNNCell(\n",
    "    num_tokens=num_tokens,\n",
    "    embedding_size=embedding_size,\n",
    "    hidden_embedding_size=hidden_embedding_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_state = rnn_cell.get_start_state(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = get_random_chunk(batch_size=batch_size, seq_length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83, 50, 63,  1, 55, 50, 57,  1, 59, 55, 61, 64, 51, 50, 58, 45,\n",
       "         5],\n",
       "       [83, 61, 50, 54, 13,  0, 53,  1, 48, 59, 61, 59, 51, 45, 58, 55,\n",
       "        45],\n",
       "       [83, 62, 55, 56, 53, 67, 45, 58, 73, 76,  5,  1, 53,  1, 66, 56,\n",
       "        50],\n",
       "       [83, 53,  5,  0, 47, 58, 53, 57, 45, 63, 73,  1, 47, 45, 57,  1,\n",
       "        49],\n",
       "       [83, 67,  7,  0,  0,  0,  0, 40, 40, 40, 38, 26, 26, 26,  0,  0,\n",
       "        58],\n",
       "       [83,  1, 47, 50, 61, 53, 63, 73,  5,  0, 55, 45, 52, 45, 63, 73,\n",
       "        62],\n",
       "       [83, 45, 47, 53, 56,  1, 55, 58, 53, 48, 53,  5,  0, 53,  1, 60,\n",
       "        59],\n",
       "       [83, 63, 59,  1, 47,  1, 57, 53, 61, 50,  1, 47, 72, 69, 50,  1,\n",
       "        58]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_loop(rnn_cell, batch_indices):\n",
    "    batch_size = batch_indices.shape[0]\n",
    "    seq_length = batch_indices.shape[1]\n",
    "\n",
    "    last_hidden_state = rnn_cell.get_start_state(batch_size)\n",
    "    \n",
    "    all_logits = []\n",
    "\n",
    "    for i in range(1, seq_length):\n",
    "        input = torch.LongTensor(batch_indices[:, i]).unsqueeze(dim=-1)\n",
    "        assert input.shape == (batch_size, 1)\n",
    "        output = rnn_cell(input, last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Not equal shapes: torch.Size([8, 49]) instead of (8, 80)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrnn_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnn_cell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m, in \u001b[0;36mrnn_loop\u001b[0;34m(rnn_cell, batch_indices)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(batch_indices[:, i])\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (batch_size, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mrnn_cell\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_hidden_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[7], line 28\u001b[0m, in \u001b[0;36mRNNCell.forward\u001b[0;34m(self, input, last_hidden_state)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# (batch, embedding_size + hidden_embedding_size)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m concat_input_and_last_hidden \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;28minput\u001b[39m, last_hidden_state], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[43massert_check_shapes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcat_input_and_last_hidden\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_embedding_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# (batch, hidden_embedding_size)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m new_hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_to_new_hidden(concat_input_and_last_hidden)\n",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m, in \u001b[0;36massert_check_shapes\u001b[0;34m(lhs_shape, rhs_shape)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_check_shapes\u001b[39m(lhs_shape, rhs_shape):\n\u001b[1;32m      2\u001b[0m     assertion_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot equal shapes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlhs_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrhs_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m lhs_shape \u001b[38;5;241m==\u001b[39m rhs_shape, assertion_message\n",
      "\u001b[0;31mAssertionError\u001b[0m: Not equal shapes: torch.Size([8, 49]) instead of (8, 80)"
     ]
    }
   ],
   "source": [
    "rnn_loop(rnn_cell, chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
