{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('onegin.txt', 'r') as iofile:\n",
    "    text = iofile.readlines()\n",
    "    \n",
    "text = \"\".join([x.replace('\\t\\t', '').lower() for x in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_tokens: 84\n"
     ]
    }
   ],
   "source": [
    "SOS_TOKEN = '<sos>'\n",
    "tokens = sorted(set(text.lower())) + [SOS_TOKEN]\n",
    "\n",
    "num_tokens = len(tokens)\n",
    "\n",
    "print(f\"num_tokens: {num_tokens}\")\n",
    "\n",
    "token_to_index = {token : index for index, token in enumerate(tokens)}\n",
    "index_to_token = {index : token for index, token in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_indices = [token_to_index[token] for token in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_chunk(batch_size, seq_length):\n",
    "    text_len = len(text)\n",
    "    # start_index in [0, text_len - seq_length - 1]\n",
    "    start_indices = np.random.randint(low=0, high=text_len - seq_length, size=batch_size)\n",
    "    random_chunks = [[token_to_index[SOS_TOKEN]] + text_indices[start_index:start_index + seq_length] for start_index in start_indices]\n",
    "    random_chunks = np.array(random_chunks)\n",
    "    assert random_chunks.shape == (batch_size, seq_length + 1)\n",
    "    return random_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_check_shapes(lhs_shape, rhs_shape):\n",
    "    assertion_message = f\"Not equal shapes: {lhs_shape} instead of {rhs_shape}\"\n",
    "    assert lhs_shape == rhs_shape, assertion_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell(nn.Module):\n",
    "    def __init__(self, num_tokens, embedding_size, hidden_embedding_size):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.num_tokens = num_tokens\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_embedding_size = hidden_embedding_size\n",
    "\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=num_tokens, embedding_dim=embedding_size)\n",
    "\n",
    "        # input shape:              (batch_size, 1)\n",
    "        # with embeds shape:        (batch_size, embedding_size)\n",
    "        # last hidden state shape:  (batch_size, hidden_embedding_size)\n",
    "        self.W_to_new_hidden = nn.Linear(embedding_size + hidden_embedding_size, hidden_embedding_size)\n",
    "        self.W_to_raw_logits = nn.Linear(hidden_embedding_size, num_tokens)\n",
    "\n",
    "    def forward(self, input, last_hidden_state):\n",
    "        batch_size = input.shape[0]\n",
    "\n",
    "        # (batch, embedding_size)\n",
    "        input_embeddings = self.embedding_layer(input).squeeze(dim=1)\n",
    "        assert_check_shapes(\n",
    "            input_embeddings.shape, \n",
    "            (batch_size, self.embedding_size)\n",
    "        )\n",
    "\n",
    "        # (batch, embedding_size + hidden_embedding_size)\n",
    "        concat_input_and_last_hidden = torch.cat([input_embeddings, last_hidden_state], dim=-1)\n",
    "        assert_check_shapes(\n",
    "            concat_input_and_last_hidden.shape, \n",
    "            (batch_size, self.embedding_size + self.hidden_embedding_size)\n",
    "        )\n",
    "\n",
    "        # (batch, hidden_embedding_size)\n",
    "        new_hidden_state = self.W_to_new_hidden(concat_input_and_last_hidden)\n",
    "        assert_check_shapes(\n",
    "            new_hidden_state.shape, (batch_size, self.hidden_embedding_size)\n",
    "        )\n",
    "\n",
    "        # (batch, num_tokens)\n",
    "        raw_logits = self.W_to_raw_logits(new_hidden_state)\n",
    "        assert_check_shapes(\n",
    "            raw_logits.shape, \n",
    "            (batch_size, self.num_tokens)\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'raw_logits' : raw_logits,\n",
    "            'hidden_state' : new_hidden_state\n",
    "        }\n",
    "    \n",
    "    def get_start_state(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_embedding_size, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 32\n",
    "hidden_embedding_size = 48\n",
    "batch_size = 8\n",
    "seq_length = 50\n",
    "assert num_tokens == len(tokens)\n",
    "\n",
    "rnn_cell = RNNCell(\n",
    "    num_tokens=num_tokens,\n",
    "    embedding_size=embedding_size,\n",
    "    hidden_embedding_size=hidden_embedding_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_state = rnn_cell.get_start_state(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = get_random_chunk(batch_size=batch_size, seq_length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83, 59, 57,  1, 45, 47, 63, 59, 61,  1, 52, 58, 45, 50, 63,  1,\n",
       "        46, 59, 56, 50,  0, 60, 61, 53, 61, 59, 49, 64,  5,  1, 68, 50,\n",
       "        57,  1, 69, 45, 63, 59, 46, 61, 53, 45, 58,  5,  0, 45,  1, 57,\n",
       "        50, 51, 49],\n",
       "       [83,  1, 46, 50, 52,  1, 67, 50, 56, 53,  5,  0, 49, 59, 62, 63,\n",
       "        64, 60, 58, 72, 54,  1, 68, 64, 47, 62, 63, 47, 64,  1, 59, 49,\n",
       "        58, 59, 57, 64, 13,  0, 53,  1, 60, 64, 63, 50, 69, 50, 62, 63,\n",
       "        47, 53, 76],\n",
       "       [83,  0, 55, 64, 49, 45,  1, 60, 59,  1, 58, 50, 57,  1, 62, 47,\n",
       "        59, 54,  1, 46, 72, 62, 63, 61, 72, 54,  1, 46, 50, 48,  0,  0,\n",
       "         0,  0, 40, 28,  0,  0, 62, 63, 61, 50, 57, 53, 63,  1, 59, 58,\n",
       "        50, 48, 53],\n",
       "       [83, 46, 50, 62, 60, 50, 68, 58, 59, 54,  1, 60, 61, 50, 56, 50,\n",
       "        62, 63, 73, 75,  1, 57, 53, 56, 45,  5,  0, 59, 58, 45,  1, 62,\n",
       "        53, 49, 50, 56, 45,  1, 64,  1, 62, 63, 59, 56, 45,  0, 62,  1,\n",
       "        46, 56, 50],\n",
       "       [83, 72, 66,  1, 49, 64, 66, 59, 47,  1, 53,  1, 60, 61, 59,  1,\n",
       "        49, 50, 47, 53, 67, 13,  0, 45,  1, 58, 72, 58, 68, 50,  1, 47,\n",
       "        62, 77,  1, 57, 58, 50,  1, 63, 77, 57, 58, 59,  5,  1, 63, 45,\n",
       "        58, 76, 12],\n",
       "       [83, 52, 57, 76, 63, 50, 51, 58, 59,  1, 61, 45, 62, 67, 47, 50,\n",
       "        63, 45, 56,  5,  0, 68, 53, 63, 45, 56,  1, 59, 66, 59, 63, 58,\n",
       "        59,  1, 45, 60, 64, 56, 50, 76,  5,  0, 45,  1, 67, 53, 67, 50,\n",
       "        61, 59, 58],\n",
       "       [83, 60, 61, 59, 62, 63, 53,  1, 51,  1, 53,  1, 63, 72,  5,  1,\n",
       "        57, 59, 54,  1, 62, 60, 64, 63, 58, 53, 55,  1, 62, 63, 61, 45,\n",
       "        58, 58, 72, 54,  5,  0, 53,  1, 63, 72,  5,  1, 57, 59, 54,  1,\n",
       "        47, 50, 61],\n",
       "       [83, 59,  1, 62, 55, 45, 52, 45, 56,  1, 62, 45, 63, 53, 61, 53,\n",
       "        55,  2,  0, 43, 68, 64, 51, 59, 48, 59,  1, 63, 59, 56, 55, 45,\n",
       "        44,  1, 66, 53, 63, 61, 72, 54,  1, 56, 53, 61, 53, 55,  0, 64,\n",
       "        51, 50, 56]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_loop(rnn_cell, batch_indices):\n",
    "    batch_size = batch_indices.shape[0]\n",
    "    seq_length = batch_indices.shape[1]\n",
    "    \n",
    "    last_hidden_state = rnn_cell.get_start_state(batch_size)\n",
    "    \n",
    "    all_logits = []\n",
    "    true_tokens = []\n",
    "\n",
    "    for i in range(0, seq_length):\n",
    "        input = torch.LongTensor(batch_indices[:, i]).unsqueeze(dim=-1)\n",
    "        assert input.shape == (batch_size, 1)\n",
    "        output = rnn_cell(input, last_hidden_state)\n",
    "        \n",
    "        all_logits.append(output['raw_logits'])\n",
    "        true_tokens.append(input)\n",
    "\n",
    "        last_hidden_state = output['hidden_state']\n",
    "\n",
    "    stacked_logits = torch.stack(all_logits, dim=1)\n",
    "    assert_check_shapes(\n",
    "        stacked_logits.shape, \n",
    "        (batch_size, seq_length, num_tokens)\n",
    "    )\n",
    "\n",
    "    stacked_true_tokens = torch.stack(true_tokens, dim=-1).squeeze(dim=1)\n",
    "    assert_check_shapes(\n",
    "        stacked_true_tokens.shape,\n",
    "        (batch_size, seq_length - 1)\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'stacked_logits' : stacked_logits,\n",
    "        'true_tokens' : stacked_true_tokens\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Not equal shapes: torch.Size([8, 51]) instead of (8, 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mrnn_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnn_cell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[66], line 27\u001b[0m, in \u001b[0;36mrnn_loop\u001b[0;34m(rnn_cell, batch_indices)\u001b[0m\n\u001b[1;32m     21\u001b[0m assert_check_shapes(\n\u001b[1;32m     22\u001b[0m     stacked_logits\u001b[38;5;241m.\u001b[39mshape, \n\u001b[1;32m     23\u001b[0m     (batch_size, seq_length, num_tokens)\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m stacked_true_tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(true_tokens, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[43massert_check_shapes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstacked_true_tokens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstacked_logits\u001b[39m\u001b[38;5;124m'\u001b[39m : stacked_logits,\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m : stacked_true_tokens\n\u001b[1;32m     34\u001b[0m }\n",
      "Cell \u001b[0;32mIn[60], line 3\u001b[0m, in \u001b[0;36massert_check_shapes\u001b[0;34m(lhs_shape, rhs_shape)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_check_shapes\u001b[39m(lhs_shape, rhs_shape):\n\u001b[1;32m      2\u001b[0m     assertion_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot equal shapes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlhs_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrhs_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m lhs_shape \u001b[38;5;241m==\u001b[39m rhs_shape, assertion_message\n",
      "\u001b[0;31mAssertionError\u001b[0m: Not equal shapes: torch.Size([8, 51]) instead of (8, 50)"
     ]
    }
   ],
   "source": [
    "res = rnn_loop(rnn_cell, chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 49, 84])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['stacked_logits'][:, :-1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 50])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['true_tokens'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
