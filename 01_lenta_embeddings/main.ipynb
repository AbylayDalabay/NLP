{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e64985e-b564-4cda-8d31-386ab13367a2",
   "metadata": {},
   "source": [
    "## Задание\n",
    "\n",
    "1. Мы будем работать с (частичными) данными lenta.ru отсюда: https://www.kaggle.com/yutkin/corpus-of-russian-news-articles-from-lenta/\n",
    "2. Проведите препроцессинг текста. Разбейте данные на train и test для задачи классификации (в качестве метки класса будем использовать поле topic). В качестве данных для классификации в пунктах 3 и 5 возьмите\n",
    "    - только заголовки (title)\n",
    "    - только тексты новости (text)\n",
    "    - и то, и другое\n",
    "3. Обучите fastText для классификации текстов по темам. Сравните качество для разных данных из п. 2.\n",
    "4. Обучите свою модель w2v (или возьмите любую подходящую предобученную модель). Реализуйте функцию для вычисления вектора текста / заголовка / текста+заголовка как среднего вектора входящих в него слов. \n",
    "     - (Бонус) Модифицируйте функцию вычисления среднего вектора: взвешивайте вектора слов соответствующими весами tf-idf.\n",
    "5. Обучите на полученных средних векторах алгоритм классификации, сравните полученное качество с классификатором fastText. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95387630-8069-494d-b3ac-6c36db7222ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in /opt/conda/lib/python3.11/site-packages (0.9.3)\n",
      "Requirement already satisfied: pybind11>=2.2 in /opt/conda/lib/python3.11/site-packages (from fasttext) (2.13.6)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from fasttext) (72.1.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from fasttext) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymystem3 -q\n",
    "!pip install fasttext\n",
    "\n",
    "import os\n",
    "os.environ['http_proxy'] = \"http://proxy-ws.cbank.kz:8080\"\n",
    "os.environ['https_proxy'] = \"http://proxy-ws.cbank.kz:8080\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acf7059-b9dd-402f-bf8e-db4767ab350a",
   "metadata": {},
   "source": [
    "### Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d0e64d2-1be2-4f91-a92f-91e10b60a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -O data/lenta-ru-news-part.csv https://www.dropbox.com/s/ja23c9l1ppo9ix7/lenta-ru-news-part.csv?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "503e09c1-7fd7-4316-b8db-da6247ce116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle datasets download -d yutkin/corpus-of-russian-news-articles-from-lenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7135ca6b-cb6b-49ee-be9b-77505a6bdc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167192f0-f86d-41e0-b6c1-5b08df10d427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip data/archive.zip -d data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8a9fbd5-d355-432e-ae9a-2915f425e56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1914. Русские войска вступили в пределы Венгрии</td>\n",
       "      <td>Бои у Сопоцкина и Друскеник закончились отступ...</td>\n",
       "      <td>Библиотека</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1914. Празднование столетия М.Ю. Лермонтова от...</td>\n",
       "      <td>Министерство народного просвещения, в виду про...</td>\n",
       "      <td>Библиотека</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1914. Das ist Nesteroff!</td>\n",
       "      <td>Штабс-капитан П. Н. Нестеров на днях, увидев в...</td>\n",
       "      <td>Библиотека</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1914. Бульдог-гонец под Льежем</td>\n",
       "      <td>Фотограф-корреспондент Daily Mirror рассказыва...</td>\n",
       "      <td>Библиотека</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1914. Под Люблином пойман швабский зверь</td>\n",
       "      <td>Лица, приехавшие в Варшаву из Люблина, передаю...</td>\n",
       "      <td>Библиотека</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  1914. Русские войска вступили в пределы Венгрии     \n",
       "1  1914. Празднование столетия М.Ю. Лермонтова от...   \n",
       "2                           1914. Das ist Nesteroff!   \n",
       "3                    1914. Бульдог-гонец под Льежем    \n",
       "4           1914. Под Люблином пойман швабский зверь   \n",
       "\n",
       "                                                text       topic  \n",
       "0  Бои у Сопоцкина и Друскеник закончились отступ...  Библиотека  \n",
       "1  Министерство народного просвещения, в виду про...  Библиотека  \n",
       "2  Штабс-капитан П. Н. Нестеров на днях, увидев в...  Библиотека  \n",
       "3  Фотограф-корреспондент Daily Mirror рассказыва...  Библиотека  \n",
       "4  Лица, приехавшие в Варшаву из Люблина, передаю...  Библиотека  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenta = pd.read_csv('data/lenta-ru-news.csv', usecols=['title', 'text', 'topic'], low_memory=False)\n",
    "lenta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d7f703-080c-4708-aef0-3cbcb939e20c",
   "metadata": {},
   "source": [
    "#### Оставим только классы которые подразумевались в задании"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d006f085-7275-44e6-b3bc-578751ce3ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_topics = [\n",
    "    'Экономика',\n",
    "    'Спорт',\n",
    "    'Культура',\n",
    "    'Наука и техника',\n",
    "    'Бизнес'\n",
    "] \n",
    "\n",
    "lenta = lenta[lenta['topic'].isin(target_topics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "892cc50d-30a3-4e5c-84e0-fa1ede9601f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "Экономика          79528\n",
       "Спорт              64413\n",
       "Культура           53797\n",
       "Наука и техника    53136\n",
       "Бизнес              7399\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenta.topic.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba00946-71a3-46cd-9d3b-782f84576f8e",
   "metadata": {},
   "source": [
    "### Препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f19a160-cf3d-400e-80ea-c05e939d0b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_analyzer = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bbdb3b7-f30d-4044-bd7f-88d9b2fc78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_stopwords = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3612d289-7723-4074-95b1-d30501260add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    tokens = mystem_analyzer.lemmatize(text)\n",
    "    word_tokens = [token for token in tokens if token.isalpha()]\n",
    "    return word_tokens\n",
    "\n",
    "def clean_stopwords(tokens):\n",
    "    non_stopword_tokens = [token for token in tokens if token not in russian_stopwords]\n",
    "    return non_stopword_tokens\n",
    "\n",
    "def preprocess_text(text):\n",
    "    lemma_tokens = lemmatize(text.lower())\n",
    "    clean_tokens = clean_stopwords(lemma_tokens)\n",
    "    return ' '.join(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5be3d205-562e-40fa-8c9b-92dd2fb9ca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7760630e-5ddb-4457-97ab-3fcfde92d33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenta = lenta[lenta.title.apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "lenta = lenta[lenta.text.apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "lenta = lenta[lenta.title.notna()]\n",
    "\n",
    "lenta = lenta[lenta.text.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4004d824-196f-426b-9a21-246336489591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenta_lemmatized is already exists\n"
     ]
    }
   ],
   "source": [
    "lenta_lemmatized_path = os.path.join(data_dir, 'lenta_lemmatized.csv')\n",
    "\n",
    "if not os.path.exists(lenta_lemmatized_path):\n",
    "    lenta['title_lemma'] = lenta['title'].progress_apply(preprocess_text)\n",
    "\n",
    "    lenta['text_lemma'] = lenta['text'].progress_apply(preprocess_text)\n",
    "\n",
    "    lenta.to_csv(os.path.join(data_dir, 'lenta_lemmatized.csv'), index=False)\n",
    "else:\n",
    "    print(\"lenta_lemmatized is already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c741b4b4-6a8c-4829-a037-270d0c24902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenta_lemmatized = pd.read_csv(os.path.join(data_dir, 'lenta_lemmatized.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f673f9c9-a94f-46eb-817c-6cec0f129c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenta_lemmatized = lenta_lemmatized[\n",
    "    lenta_lemmatized['text_lemma'].apply(lambda x: isinstance(x, str)) & \n",
    "    lenta_lemmatized['title_lemma'].apply(lambda x: isinstance(x, str))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1333b765-4cc2-4b17-98c6-7eb70e04a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert lenta_lemmatized['text_lemma'].apply(lambda x: isinstance(x, str)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9abf7582-287f-4bea-aa9a-e84b45f085b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert lenta_lemmatized['title_lemma'].apply(lambda x: isinstance(x, str)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ca061a1-a967-4551-8468-b254705fa7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>title_lemma</th>\n",
       "      <th>text_lemma</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Телеканалы станут вещать по единому тарифу</th>\n",
       "      <td>С 1 января 2000 года все телеканалы будут опла...</td>\n",
       "      <td>Экономика</td>\n",
       "      <td>телеканал становиться вещать единый тариф</td>\n",
       "      <td>январь год весь телеканал оплачивать услуга пе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volkswagen выкупает остатки акций \"Шкоды\"</th>\n",
       "      <td>Германский автопромышленный концерн Volkswagen...</td>\n",
       "      <td>Экономика</td>\n",
       "      <td>volkswagen выкупать остаток акция шкода</td>\n",
       "      <td>германский автопромышленный концерн volkswagen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Прибыль Тюменнефтегаза возросла в 10 раз</th>\n",
       "      <td>Нераспределенная прибыль ОАО \"Тюменнефтегаз\", ...</td>\n",
       "      <td>Экономика</td>\n",
       "      <td>прибыль тюменнефтегаз возрастать</td>\n",
       "      <td>нераспределенный прибыль оао тюменнефтегаз доч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Крупнейшее в истории слияние компаний происходит в США</th>\n",
       "      <td>Две крупнейших телекоммуникационных компании С...</td>\n",
       "      <td>Экономика</td>\n",
       "      <td>крупный история слияние компания происходить сша</td>\n",
       "      <td>крупный телекоммуникационный компания сша дост...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ГАЗ получил четверть обещанного кредита</th>\n",
       "      <td>ОАО \"ГАЗ\" и Нижегородский банк Сбербанка Росси...</td>\n",
       "      <td>Экономика</td>\n",
       "      <td>газ получать четверть обещать кредит</td>\n",
       "      <td>оао газ нижегородский банк сбербанк россия под...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 text  \\\n",
       "title                                                                                                   \n",
       "Телеканалы станут вещать по единому тарифу          С 1 января 2000 года все телеканалы будут опла...   \n",
       "Volkswagen выкупает остатки акций \"Шкоды\"           Германский автопромышленный концерн Volkswagen...   \n",
       "Прибыль Тюменнефтегаза возросла в 10 раз            Нераспределенная прибыль ОАО \"Тюменнефтегаз\", ...   \n",
       "Крупнейшее в истории слияние компаний происходи...  Две крупнейших телекоммуникационных компании С...   \n",
       "ГАЗ получил четверть обещанного кредита             ОАО \"ГАЗ\" и Нижегородский банк Сбербанка Росси...   \n",
       "\n",
       "                                                        topic  \\\n",
       "title                                                           \n",
       "Телеканалы станут вещать по единому тарифу          Экономика   \n",
       "Volkswagen выкупает остатки акций \"Шкоды\"           Экономика   \n",
       "Прибыль Тюменнефтегаза возросла в 10 раз            Экономика   \n",
       "Крупнейшее в истории слияние компаний происходи...  Экономика   \n",
       "ГАЗ получил четверть обещанного кредита             Экономика   \n",
       "\n",
       "                                                                                         title_lemma  \\\n",
       "title                                                                                                  \n",
       "Телеканалы станут вещать по единому тарифу                 телеканал становиться вещать единый тариф   \n",
       "Volkswagen выкупает остатки акций \"Шкоды\"                    volkswagen выкупать остаток акция шкода   \n",
       "Прибыль Тюменнефтегаза возросла в 10 раз                            прибыль тюменнефтегаз возрастать   \n",
       "Крупнейшее в истории слияние компаний происходи...  крупный история слияние компания происходить сша   \n",
       "ГАЗ получил четверть обещанного кредита                         газ получать четверть обещать кредит   \n",
       "\n",
       "                                                                                           text_lemma  \n",
       "title                                                                                                  \n",
       "Телеканалы станут вещать по единому тарифу          январь год весь телеканал оплачивать услуга пе...  \n",
       "Volkswagen выкупает остатки акций \"Шкоды\"           германский автопромышленный концерн volkswagen...  \n",
       "Прибыль Тюменнефтегаза возросла в 10 раз            нераспределенный прибыль оао тюменнефтегаз доч...  \n",
       "Крупнейшее в истории слияние компаний происходи...  крупный телекоммуникационный компания сша дост...  \n",
       "ГАЗ получил четверть обещанного кредита             оао газ нижегородский банк сбербанк россия под...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenta_lemmatized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6e9da5-248e-417c-b12b-a55d3bec5237",
   "metadata": {},
   "source": [
    "### Train-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bff4878-9ad4-49b7-97b0-0e0b61f02a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lenta, test_lenta = train_test_split(\n",
    "    lenta_lemmatized,\n",
    "    train_size=0.7,\n",
    "    stratify=lenta_lemmatized['topic'],\n",
    "    shuffle=True,\n",
    "    random_state=667\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38642903-cd36-4bae-b6c8-5ca8e0d390f8",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f06872d-15d2-4e26-b705-42f5811383d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фасттекст хавает данные только в таком странном виде\n",
    "def write2txt(text_list, label_list, filename):\n",
    "    save_path = os.path.join(data_dir, filename + '.txt')\n",
    "    with open(save_path, 'w') as file:\n",
    "        for sentence, label in zip(text_list, label_list):\n",
    "            file.write(f\"__label__{label} {sentence}\")\n",
    "            file.write('\\n')\n",
    "\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7dee896-5bdf-4eb8-b6ce-7b60d4e10c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(\n",
    "    train_sentences, \n",
    "    train_labels,\n",
    "    test_sentences,\n",
    "    test_labels,\n",
    "    filename\n",
    "):\n",
    "    assert len(train_sentences) == len(train_labels)\n",
    "    assert len(test_sentences) == len(test_labels)\n",
    "    \n",
    "    save_path = write2txt(\n",
    "        train_sentences,\n",
    "        train_labels,\n",
    "        filename\n",
    "    )\n",
    "    \n",
    "    model = fasttext.train_supervised(save_path, wordNgrams=2)\n",
    "\n",
    "    delete_label_prefix = lambda word: word[len('__label__'):]\n",
    "    \n",
    "    predicted_labels_with_prefix = model.predict(test_sentences)[0]\n",
    "    predicted_labels = [delete_label_prefix(label[0]) for label in predicted_labels_with_prefix]\n",
    "    \n",
    "    score_accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "    micro_f1 = f1_score(test_labels, predicted_labels, average='micro')\n",
    "    macro_f1 = f1_score(test_labels, predicted_labels, average='macro')\n",
    "    weighted_f1 = f1_score(test_labels, predicted_labels, average='weighted')\n",
    "    \n",
    "    metric_entry = {\n",
    "        'accuracy' : score_accuracy,\n",
    "        'micro_f1' : micro_f1,\n",
    "        'macro_f1' : macro_f1,\n",
    "        'weighted_f1' : weighted_f1\n",
    "    }\n",
    "    \n",
    "    for name, value in metric_entry.items():\n",
    "        print(f\"{name} : {round(value, 3)}\")\n",
    "\n",
    "    return metric_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6312db68-7647-412b-a4ca-c16ab6682ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Number of words:  43035\n",
      "Number of labels: 5\n",
      "Progress: 100.0% words/sec/thread:  611494 lr:  0.000000 avg.loss:  0.089566 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.753\n",
      "micro_f1 : 0.753\n",
      "macro_f1 : 0.498\n",
      "weighted_f1 : 0.669\n"
     ]
    }
   ],
   "source": [
    "# Only on titles\n",
    "title_metrics = train_and_evaluate(\n",
    "    train_lenta['title_lemma'].tolist(),\n",
    "    train_lenta['topic'].tolist(),\n",
    "    test_lenta['title_lemma'].tolist(),\n",
    "    test_lenta['topic'].tolist(),\n",
    "    'title_lenta'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "212ced48-694b-49a1-9f91-fb2fad851869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 23M words\n",
      "Number of words:  250947\n",
      "Number of labels: 5\n",
      "Progress: 100.0% words/sec/thread: 1098730 lr:  0.000000 avg.loss:  0.108767 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.771\n",
      "micro_f1 : 0.771\n",
      "macro_f1 : 0.572\n",
      "weighted_f1 : 0.737\n"
     ]
    }
   ],
   "source": [
    "# Only on full text\n",
    "text_metrics = train_and_evaluate(\n",
    "    train_lenta['text_lemma'].tolist(),\n",
    "    train_lenta['topic'].tolist(),\n",
    "    test_lenta['text_lemma'].tolist(),\n",
    "    test_lenta['topic'].tolist(),\n",
    "    'text_lemma'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d07ad24-aa76-4b78-8deb-fd82225aab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_series(lhs, rhs):\n",
    "    return lhs.str.cat(rhs, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac5562e9-256d-4558-aca1-5e94d262742e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 25M words\n",
      "Number of words:  252060\n",
      "Number of labels: 5\n",
      "Progress: 100.0% words/sec/thread: 1116732 lr:  0.000000 avg.loss:  0.110111 ETA:   0h 0m 0ss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.772\n",
      "micro_f1 : 0.772\n",
      "macro_f1 : 0.576\n",
      "weighted_f1 : 0.74\n"
     ]
    }
   ],
   "source": [
    "# Concatenated title and text\n",
    "title_text_metrics = train_and_evaluate(\n",
    "    join_series(train_lenta['title_lemma'], train_lenta['text_lemma']).tolist(),\n",
    "    train_lenta['topic'].tolist(),\n",
    "    join_series(test_lenta['title_lemma'], test_lenta['text_lemma']).tolist(),\n",
    "    test_lenta['topic'].tolist(),\n",
    "    'text_lemma'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd5964a-1608-40cf-abf4-2bd8f933df18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dalabaya",
   "language": "python",
   "name": "dalabaya"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
